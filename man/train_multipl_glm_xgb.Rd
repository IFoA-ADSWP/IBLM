% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_multipl_glm_xgb.R
\name{train_multipl_glm_xgb}
\alias{train_multipl_glm_xgb}
\title{Train Multiplicative GLM-XGBoost Ensemble Model}
\usage{
train_multipl_glm_xgb(
  glm_model,
  x,
  y,
  vdt,
  params = list(objective = "count:poisson", eval_metric = "poisson-nloglik"),
  use_glm = F,
  p = NULL
)
}
\arguments{
\item{glm_model}{A fitted GLM model object that can be used with predict()}

\item{x}{Data frame or matrix containing features for the training data}

\item{y}{Numeric vector of actual target values for the training data}

\item{vdt}{List containing validation data with elements:
\itemize{
  \item x_val: Features for validation data
  \item y_val: Actual target values for validation data
}}

\item{params}{List of XGBoost parameters. Default includes:
\itemize{
  \item objective = "count:poisson": Loss function for Poisson regression
  \item eval_metric = "poisson-nloglik": Evaluation metric
}}

\item{use_glm}{Logical indicating whether to initialize XGBoost with GLM
predictions using base_margin. Default is FALSE}

\item{p}{Numeric parameter (currently unused in the function)}
}
\value{
An object of class "ens" containing:
  \itemize{
    \item glm_model: The original fitted GLM model
    \item xgb_model: The fitted XGBoost model trained on multiplicative corrections
  }
}
\description{
Trains an ensemble model combining GLM and XGBoost where XGBoost learns
multiplicative corrections to GLM predictions. The XGBoost model is trained
on the ratio of actual values to GLM predictions, creating a multiplicative
ensemble approach.
}
\details{
This function implements a multiplicative ensemble approach where:
\enumerate{
  \item GLM predictions are generated for both training and validation sets
  \item Target ratios are calculated as actual_values / glm_predictions
  \item XGBoost is trained to predict these ratios (multiplicative corrections)
  \item Final predictions are obtained by multiplying GLM predictions with XGBoost ratios
}

When use_glm = TRUE, the XGBoost model is initialized with GLM link predictions
as base margins, which can improve convergence and performance.

The function uses early stopping with 25 rounds and trains for a maximum of
1000 rounds, monitoring performance on the validation set.
}
\examples{
\dontrun{
# Assuming you have a fitted GLM model and prepared data
glm_fit <- glm(claims ~ age + gender, family = poisson(), data = train_data)

# Prepare validation data
val_data <- list(x_val = test_features, y_val = test_targets)

# Train ensemble model
ensemble_model <- train_multipl_glm_xgb(
  glm_model = glm_fit,
  x = train_features,
  y = train_targets,
  vdt = val_data,
  use_glm = TRUE
)
}

}
