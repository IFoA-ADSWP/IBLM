% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_glm_xgb.R
\name{train_glm_xgb}
\alias{train_glm_xgb}
\title{Train IBLM Model (with XGBoost for residuals)}
\usage{
train_glm_xgb(
  df_list,
  response_var,
  family = "poisson",
  xgb_additional_params = list(nrounds = 1000, verbose = 0, early_stopping_rounds = 25),
  strip_glm = TRUE
)
}
\arguments{
\item{df_list}{A named list containing training and validation datasets. Must have
elements named "train" and "validate", each containing df_list frames with the
same structure. This item is naturally output from the function [split_into_train_validate_test()]}

\item{response_var}{Character string specifying the name of the response variable
column in the datasets. The string MUST appear in both `df_list$train` and `df_list$validate`.}

\item{family}{Character string specifying the distributional family for the model.
Currently only "poisson", "gamma", "tweedie" and "gaussian" is fully supported. See details for how this impacts fitting.}

\item{xgb_additional_params}{Named list of additional parameters to pass to \link[xgboost]{xgb.train}}

\item{strip_glm}{TRUE/FALSE, whether to strip superfluous data from the `glm_model` object saved within `iblm` class that is output. Only serves to reduce memory constraints.}
}
\value{
An object of class "iblm" containing:
  \item{glm_model}{The fitted GLM model object}
  \item{booster_model}{The trained XGBoost model object}
}
\description{
This function trains an ensemble model combining a Generalized Linear Model (GLM)
with an XGBoost model.

The XGBoost model is trained on:
- actual responses / GLM predictions, when the link function is log
- actual responses - GLM predictions, when the link function is identity

This gets XGBoost to effectively learn the residual patterns that the GLM couldn't
capture. Optionally, GLM predictions can be used as base margins for XGBoost training.
}
\details{
The `family` argument will be fed into the GLM fitting. Default values for the XGBoost fitting are also selected based on family.

Note: Any xgboost configuration below will be overwritten by any explicit arguments input via `xgb_additional_params`

For "poisson" family the link function is 'log' and XGBoost is configured with:
\itemize{
  \item objective: "count:poisson"
  \item base_score: 1
}

For "gamma" family the link function is 'log' and XGBoost is configured with:
\itemize{
  \item objective: "reg:gamma"
  \item base_score: 1
}

For "tweedie" family the link function is 'log' (with a var.power = 1.5) and XGBoost is configured with:
\itemize{
  \item objective: "reg:tweedie"
  \item base_score: 1
  \item tweedie_variance_power = 1.5
}

For "gaussian" family the link function is 'identity' and XGBoost is configured with:
\itemize{
  \item objective: "reg:squarederror"
  \item base_score: 0
}
}
\examples{
\dontrun{
library(IBLM)

df_list <- split_into_train_validate_test(freMTPL2freq)

ensemble_model <- train_glm_xgb(df_list, response_var = "ClaimRate")
}

}
\seealso{
\link[stats]{glm}, \link[xgboost]{xgb.train}
}
