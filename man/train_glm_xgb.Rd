% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_glm_xgb.R
\name{train_glm_xgb}
\alias{train_glm_xgb}
\title{Train GLM-XGBoost Ensemble Model}
\usage{
train_glm_xgb(
  data,
  glm_model,
  response_var = "ClaimRate",
  family = "poisson",
  use_glm = FALSE,
  xbg_train_additional_params = list(nrounds = 1000, verbose = 1, early_stopping_rounds =
    25)
)
}
\arguments{
\item{data}{A named list containing training and validation datasets. Must have
elements named "train" and "validate", each containing data frames with the
same structure.}

\item{glm_model}{A fitted GLM model object (from \code{\link[stats]{glm}}) that
will be used to generate baseline predictions for the ensemble.}

\item{response_var}{Character string specifying the name of the response variable
column in the datasets. Default is "ClaimRate".}

\item{family}{Character string specifying the distributional family for the model.
Currently only "poisson" is fully supported. Default is "poisson".}

\item{use_glm}{Logical indicating whether to use GLM predictions as base margins
in XGBoost training. When TRUE, XGBoost starts from GLM link predictions rather
than zero. Default is FALSE.}

\item{xbg_train_additional_params}{Named list of additional parameters to pass to
\code{\link[xgboost]{xgb.train}}. Default includes nrounds = 1000, verbose = 1,
and early_stopping_rounds = 25.}
}
\value{
An object of class "ens" containing:
  \item{glm_model}{The input GLM model object}
  \item{xgb_model}{The trained XGBoost model object}
}
\description{
This function trains an ensemble model combining a Generalized Linear Model (GLM)
with an XGBoost model. The XGBoost model is trained on the ratio of actual responses
to GLM predictions, effectively learning the residual patterns that the GLM couldn't
capture. Optionally, GLM predictions can be used as base margins for XGBoost training.
}
\details{
The function works by:
\enumerate{
  \item Using the provided GLM model to generate predictions on training and validation sets
  \item Computing target ratios by dividing actual responses by GLM predictions
  \item Training an XGBoost model to predict these ratios
  \item Optionally using GLM link predictions as base margins if \code{use_glm = TRUE}
}

The ensemble prediction would typically be: GLM_prediction * XGBoost_prediction

For Poisson family, XGBoost is configured with:
\itemize{
  \item objective: "count:poisson"
  \item eval_metric: "poisson-nloglik"
  \item base_score: 1
}
}
\note{
\itemize{
  \item The function expects both training and validation datasets to have identical structure
  \item GLM predictions should not be zero to avoid division by zero errors
  \item Currently only supports Poisson family; other families will use default XGBoost settings
  \item The parameter name \code{xbg_train_additional_params} appears to have a typo (should be "xgb")
}
}
\examples{
\dontrun{
# Prepare data
train_data <- data.frame(
  ClaimRate = rpois(1000, 2),
  feature1 = rnorm(1000),
  feature2 = runif(1000)
)
validate_data <- data.frame(
  ClaimRate = rpois(500, 2),
  feature1 = rnorm(500),
  feature2 = runif(500)
)
data_list <- list(train = train_data, validate = validate_data)

# Fit GLM model
glm_fit <- glm(ClaimRate ~ feature1 + feature2,
               data = train_data,
               family = poisson())

# Train ensemble
ensemble_model <- train_glm_xgb(
  data = data_list,
  glm_model = glm_fit,
  use_glm = TRUE,
  xbg_train_additional_params = list(
    nrounds = 500,
    eta = 0.1,
    max_depth = 6
  )
)
}

}
\seealso{
\code{\link[stats]{glm}}, \code{\link[xgboost]{xgb.train}}, \code{\link[xgboost]{xgb.DMatrix}}
}
