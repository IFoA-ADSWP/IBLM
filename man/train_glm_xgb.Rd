% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_glm_xgb.R
\name{train_glm_xgb}
\alias{train_glm_xgb}
\title{Train GLM-XGBoost Ensemble Model}
\usage{
train_glm_xgb(
  data,
  response_var,
  family = "poisson",
  use_glm = FALSE,
  xgb_additional_params = list(nrounds = 1000, verbose = 0, early_stopping_rounds = 25)
)
}
\arguments{
\item{data}{A named list containing training and validation datasets. Must have
elements named "train" and "validate", each containing data frames with the
same structure. This item is naturally output from the function [split_into_train_validate_test()]}

\item{response_var}{Character string specifying the name of the response variable
column in the datasets. The string MUST appear in both `data$train` and `data$validate`.}

\item{family}{Character string specifying the distributional family for the model.
Currently only "poisson", "gamma", "tweedie" and "gaussian" is fully supported. See details for how this impacts fitting.}

\item{use_glm}{Logical indicating whether to use GLM predictions as base margins
in XGBoost training. When TRUE, XGBoost starts from GLM link predictions rather
than zero. Default is FALSE.}

\item{xgb_additional_params}{Named list of additional parameters to pass to
\code{\link[xgboost]{xgb.train()}}.}
}
\value{
An object of class "ens" containing:
  \item{glm_model}{The fitted GLM model object}
  \item{xgb_model}{The trained XGBoost model object}
}
\description{
This function trains an ensemble model combining a Generalized Linear Model (GLM)
with an XGBoost model.

The XGBoost model is trained on:
- actual responses / GLM predictions, when the link function is log
- actual responses - GLM predictions, when the link function is identity

This gets XGBoost to effectively learn the residual patterns that the GLM couldn't
capture. Optionally, GLM predictions can be used as base margins for XGBoost training.
}
\details{
The `family` argument will be fed into the GLM fitting. Default values for the XGBoost fitting are also selected based on family.

Note: Any xgboost configuration below will be overwritten by any explicit arguments input via `xgb_additional_params`

For "poisson" family the link function is 'log' and XGBoost is configured with:
\itemize{
  \item objective: "count:poisson"
  \item base_score: 1
}

For "gamma" family the link function is 'log' and XGBoost is configured with:
\itemize{
  \item objective: "reg:gamma"
  \item base_score: 1
}

For "tweedie" family the link function is 'log' (with a var.power = 1.5) and XGBoost is configured with:
\itemize{
  \item objective: "reg:tweedie"
  \item base_score: 1
  \item tweedie_variance_power = 1.5
}

For "gaussian" family the link function is 'identity' and XGBoost is configured with:
\itemize{
  \item objective: "reg:squarederror"
  \item base_score: 0
}
}
\examples{
\dontrun{
library(IBLM)

data <- split_into_train_validate_test(freMTPL2freq)

ensemble_model <- train_glm_xgb(data, response_var = "ClaimRate")
}

}
\seealso{
\link[stats]{glm}, \link[xgboost]{xgb.train}
}
